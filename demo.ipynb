{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone -b gpu https://github.com/shpotes/image-classification/\n",
    "%cd image-classification\n",
    "!pip install -q -r requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from model.dataset import *\n",
    "#from moutils import * \n",
    "\n",
    "#from models import LinearModel, LeNet\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json') as raw_config:\n",
    "    config = json.load(raw_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data/train/b422e266a4cb4717bd2780f80401d2f0.jpg', 1),\n",
       " ('data/train/1276cf06fcaf45f2b32fe6fc753a6a1e.jpg', 0),\n",
       " ('data/train/773f62be31ad4949b544b2c4c088f8f0.jpg', 0),\n",
       " ('data/train/bcbb7b88ffcf4002937f22b69a12cfb7.jpg', 0),\n",
       " ('data/train/8aa1209d500e4601a26644d4b4f4857e.jpg', 3)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_source = build_source_from_metadata(pd.read_csv(config['model']['metadata_path']),\n",
    "                                        config['model']['data_path'], 'train')\n",
    "train_source[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img, label, model=None, size=(32, 32)):\n",
    "    img = tf.image.resize(img, size=size)\n",
    "    img = img / 255.0\n",
    "    return img, label\n",
    "\n",
    "dataset = make_dataset(train_source, preprocess_image, training=True, batch_size=3,\n",
    "                       num_epochs=1, num_parallel_calls=4)\n",
    "dataset = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=53, shape=(3,), dtype=int32, numpy=array([1, 0, 0], dtype=int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dataset)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow_batch_of_three(next(dataset), config['model']['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModel\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 15365     \n",
      "=================================================================\n",
      "Total params: 15,365\n",
      "Trainable params: 15,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "linear_model = LinearModel(config)\n",
    "print(linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0610 03:53:47.524817 140243699922752 training_utils.py:1436] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 0.5633 - accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3474 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2875 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3172 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3121 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2892 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2577 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2268 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2031 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1891 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1837 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1824 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1802 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1740 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1639 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1520 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1408 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1315 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1245 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "test = linear_model.train(overfit_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0610 03:54:29.713122 140243699922752 training_utils.py:1436] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "182/182 [==============================] - 2s 12ms/step - loss: 0.7139 - accuracy: 0.7366\n",
      "Epoch 2/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6960 - accuracy: 0.7431\n",
      "Epoch 3/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6926 - accuracy: 0.7452\n",
      "Epoch 4/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6893 - accuracy: 0.7472\n",
      "Epoch 5/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6862 - accuracy: 0.7486\n",
      "Epoch 6/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.6832 - accuracy: 0.7490\n",
      "Epoch 7/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.6802 - accuracy: 0.7514\n",
      "Epoch 8/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6774 - accuracy: 0.7517\n",
      "Epoch 9/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.6745 - accuracy: 0.7528\n",
      "Epoch 10/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.6718 - accuracy: 0.7538\n",
      "Epoch 11/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.6691 - accuracy: 0.7555\n",
      "Epoch 12/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6664 - accuracy: 0.7569\n",
      "Epoch 13/400\n",
      "182/182 [==============================] - 2s 11ms/step - loss: 0.6637 - accuracy: 0.7583\n",
      "Epoch 14/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6612 - accuracy: 0.7593\n",
      "Epoch 15/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.6586 - accuracy: 0.7603\n",
      "Epoch 16/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.6561 - accuracy: 0.7603\n",
      "Epoch 17/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6536 - accuracy: 0.7610\n",
      "Epoch 18/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6512 - accuracy: 0.7620\n",
      "Epoch 19/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6488 - accuracy: 0.7638\n",
      "Epoch 20/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6464 - accuracy: 0.7651\n",
      "Epoch 21/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6441 - accuracy: 0.7669\n",
      "Epoch 22/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6418 - accuracy: 0.7672\n",
      "Epoch 23/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6395 - accuracy: 0.7686\n",
      "Epoch 24/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6373 - accuracy: 0.7703\n",
      "Epoch 25/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6350 - accuracy: 0.7713\n",
      "Epoch 26/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6329 - accuracy: 0.7730\n",
      "Epoch 27/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6307 - accuracy: 0.7741\n",
      "Epoch 28/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6286 - accuracy: 0.7758\n",
      "Epoch 29/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6264 - accuracy: 0.7768\n",
      "Epoch 30/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6244 - accuracy: 0.7782\n",
      "Epoch 31/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6223 - accuracy: 0.7789\n",
      "Epoch 32/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.6203 - accuracy: 0.7792\n",
      "Epoch 33/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.6182 - accuracy: 0.7806\n",
      "Epoch 34/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6162 - accuracy: 0.7806\n",
      "Epoch 35/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6143 - accuracy: 0.7806\n",
      "Epoch 36/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6123 - accuracy: 0.7809\n",
      "Epoch 37/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6104 - accuracy: 0.7816\n",
      "Epoch 38/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6085 - accuracy: 0.7827\n",
      "Epoch 39/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.6066 - accuracy: 0.7844\n",
      "Epoch 40/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6047 - accuracy: 0.7858\n",
      "Epoch 41/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6029 - accuracy: 0.7858\n",
      "Epoch 42/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6010 - accuracy: 0.7865\n",
      "Epoch 43/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5992 - accuracy: 0.7868\n",
      "Epoch 44/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5974 - accuracy: 0.7871\n",
      "Epoch 45/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5956 - accuracy: 0.7882\n",
      "Epoch 46/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5939 - accuracy: 0.7889\n",
      "Epoch 47/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5921 - accuracy: 0.7895\n",
      "Epoch 48/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5904 - accuracy: 0.7906\n",
      "Epoch 49/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5887 - accuracy: 0.7920\n",
      "Epoch 50/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5870 - accuracy: 0.7923\n",
      "Epoch 51/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5853 - accuracy: 0.7933\n",
      "Epoch 52/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.5837 - accuracy: 0.7940\n",
      "Epoch 53/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.5820 - accuracy: 0.7947\n",
      "Epoch 54/400\n",
      "182/182 [==============================] - 2s 11ms/step - loss: 0.5804 - accuracy: 0.7950\n",
      "Epoch 55/400\n",
      "182/182 [==============================] - 2s 11ms/step - loss: 0.5788 - accuracy: 0.7950\n",
      "Epoch 56/400\n",
      "182/182 [==============================] - 2s 10ms/step - loss: 0.5772 - accuracy: 0.7964\n",
      "Epoch 57/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.5756 - accuracy: 0.7971\n",
      "Epoch 58/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5740 - accuracy: 0.7981\n",
      "Epoch 59/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5724 - accuracy: 0.7985\n",
      "Epoch 60/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.5709 - accuracy: 0.7988\n",
      "Epoch 61/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5693 - accuracy: 0.7988\n",
      "Epoch 62/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.5678 - accuracy: 0.7995\n",
      "Epoch 63/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.5663 - accuracy: 0.8002\n",
      "Epoch 64/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5648 - accuracy: 0.8009\n",
      "Epoch 65/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5633 - accuracy: 0.8016\n",
      "Epoch 66/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5618 - accuracy: 0.8016\n",
      "Epoch 67/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5604 - accuracy: 0.8016\n",
      "Epoch 68/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5589 - accuracy: 0.8026\n",
      "Epoch 69/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5575 - accuracy: 0.8033\n",
      "Epoch 70/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5560 - accuracy: 0.8033\n",
      "Epoch 71/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5546 - accuracy: 0.8043\n",
      "Epoch 72/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5532 - accuracy: 0.8050\n",
      "Epoch 73/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5518 - accuracy: 0.8054\n",
      "Epoch 74/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5504 - accuracy: 0.8061\n",
      "Epoch 75/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5491 - accuracy: 0.8074\n",
      "Epoch 76/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5477 - accuracy: 0.8074\n",
      "Epoch 77/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5463 - accuracy: 0.8085\n",
      "Epoch 78/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5450 - accuracy: 0.8091\n",
      "Epoch 79/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5437 - accuracy: 0.8091\n",
      "Epoch 80/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5423 - accuracy: 0.8091\n",
      "Epoch 81/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.5410 - accuracy: 0.8091\n",
      "Epoch 82/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5397 - accuracy: 0.8095\n",
      "Epoch 83/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5384 - accuracy: 0.8102\n",
      "Epoch 84/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5371 - accuracy: 0.8105\n",
      "Epoch 85/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5359 - accuracy: 0.8119\n",
      "Epoch 86/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5346 - accuracy: 0.8119\n",
      "Epoch 87/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5333 - accuracy: 0.8126\n",
      "Epoch 88/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5321 - accuracy: 0.8133\n",
      "Epoch 89/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5308 - accuracy: 0.8140\n",
      "Epoch 90/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5296 - accuracy: 0.8150\n",
      "Epoch 91/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5284 - accuracy: 0.8150\n",
      "Epoch 92/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5272 - accuracy: 0.8150\n",
      "Epoch 93/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5260 - accuracy: 0.8153\n",
      "Epoch 94/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5248 - accuracy: 0.8153\n",
      "Epoch 95/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5236 - accuracy: 0.8157\n",
      "Epoch 96/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5224 - accuracy: 0.8157\n",
      "Epoch 97/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5212 - accuracy: 0.8160\n",
      "Epoch 98/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5200 - accuracy: 0.8160\n",
      "Epoch 99/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5189 - accuracy: 0.8167\n",
      "Epoch 100/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5177 - accuracy: 0.8171\n",
      "Epoch 101/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5166 - accuracy: 0.8177\n",
      "Epoch 102/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5154 - accuracy: 0.8184\n",
      "Epoch 103/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5143 - accuracy: 0.8188\n",
      "Epoch 104/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5132 - accuracy: 0.8191\n",
      "Epoch 105/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5121 - accuracy: 0.8191\n",
      "Epoch 106/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5110 - accuracy: 0.8198\n",
      "Epoch 107/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5099 - accuracy: 0.8212\n",
      "Epoch 108/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5088 - accuracy: 0.8222\n",
      "Epoch 109/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5077 - accuracy: 0.8232\n",
      "Epoch 110/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5066 - accuracy: 0.8243\n",
      "Epoch 111/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5055 - accuracy: 0.8246\n",
      "Epoch 112/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5045 - accuracy: 0.8253\n",
      "Epoch 113/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5034 - accuracy: 0.8257\n",
      "Epoch 114/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5023 - accuracy: 0.8263\n",
      "Epoch 115/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5013 - accuracy: 0.8267\n",
      "Epoch 116/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5003 - accuracy: 0.8270\n",
      "Epoch 117/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4992 - accuracy: 0.8274\n",
      "Epoch 118/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4982 - accuracy: 0.8277\n",
      "Epoch 119/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4972 - accuracy: 0.8281\n",
      "Epoch 120/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4962 - accuracy: 0.8291\n",
      "Epoch 121/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4951 - accuracy: 0.8294\n",
      "Epoch 122/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4941 - accuracy: 0.8301\n",
      "Epoch 123/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4931 - accuracy: 0.8301\n",
      "Epoch 124/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4921 - accuracy: 0.8301\n",
      "Epoch 125/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4912 - accuracy: 0.8301\n",
      "Epoch 126/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4902 - accuracy: 0.8305\n",
      "Epoch 127/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4892 - accuracy: 0.8305\n",
      "Epoch 128/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4882 - accuracy: 0.8308\n",
      "Epoch 129/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4873 - accuracy: 0.8312\n",
      "Epoch 130/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4863 - accuracy: 0.8315\n",
      "Epoch 131/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4854 - accuracy: 0.8332\n",
      "Epoch 132/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4844 - accuracy: 0.8332\n",
      "Epoch 133/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4835 - accuracy: 0.8336\n",
      "Epoch 134/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4825 - accuracy: 0.8343\n",
      "Epoch 135/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4816 - accuracy: 0.8343\n",
      "Epoch 136/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4807 - accuracy: 0.8343\n",
      "Epoch 137/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4797 - accuracy: 0.8343\n",
      "Epoch 138/400\n",
      "182/182 [==============================] - 2s 10ms/step - loss: 0.4788 - accuracy: 0.8339\n",
      "Epoch 139/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4779 - accuracy: 0.8339\n",
      "Epoch 140/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4770 - accuracy: 0.8339\n",
      "Epoch 141/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4761 - accuracy: 0.8343\n",
      "Epoch 142/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4752 - accuracy: 0.8343\n",
      "Epoch 143/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4743 - accuracy: 0.8343\n",
      "Epoch 144/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4734 - accuracy: 0.8349\n",
      "Epoch 145/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4726 - accuracy: 0.8353\n",
      "Epoch 146/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4717 - accuracy: 0.8353\n",
      "Epoch 147/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.4708 - accuracy: 0.8356\n",
      "Epoch 148/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.4699 - accuracy: 0.8360\n",
      "Epoch 149/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4691 - accuracy: 0.8360\n",
      "Epoch 150/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4682 - accuracy: 0.8363\n",
      "Epoch 151/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4674 - accuracy: 0.8367\n",
      "Epoch 152/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4665 - accuracy: 0.8367\n",
      "Epoch 153/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4657 - accuracy: 0.8377\n",
      "Epoch 154/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4648 - accuracy: 0.8384\n",
      "Epoch 155/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.4640 - accuracy: 0.8391\n",
      "Epoch 156/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.4631 - accuracy: 0.8391\n",
      "Epoch 157/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4623 - accuracy: 0.8404\n",
      "Epoch 158/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4615 - accuracy: 0.8404\n",
      "Epoch 159/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4607 - accuracy: 0.8404\n",
      "Epoch 160/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4599 - accuracy: 0.8408\n",
      "Epoch 161/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4590 - accuracy: 0.8411\n",
      "Epoch 162/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4582 - accuracy: 0.8411\n",
      "Epoch 163/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4574 - accuracy: 0.8411\n",
      "Epoch 164/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4566 - accuracy: 0.8422\n",
      "Epoch 165/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4558 - accuracy: 0.8422\n",
      "Epoch 166/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4550 - accuracy: 0.8432\n",
      "Epoch 167/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4543 - accuracy: 0.8435\n",
      "Epoch 168/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4535 - accuracy: 0.8442\n",
      "Epoch 169/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4527 - accuracy: 0.8446\n",
      "Epoch 170/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4519 - accuracy: 0.8453\n",
      "Epoch 171/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4511 - accuracy: 0.8459\n",
      "Epoch 172/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4504 - accuracy: 0.8463\n",
      "Epoch 173/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4496 - accuracy: 0.8463\n",
      "Epoch 174/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4488 - accuracy: 0.8473\n",
      "Epoch 175/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4481 - accuracy: 0.8480\n",
      "Epoch 176/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4473 - accuracy: 0.8490\n",
      "Epoch 177/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4466 - accuracy: 0.8497\n",
      "Epoch 178/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4458 - accuracy: 0.8501\n",
      "Epoch 179/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4451 - accuracy: 0.8504\n",
      "Epoch 180/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4443 - accuracy: 0.8504\n",
      "Epoch 181/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4436 - accuracy: 0.8508\n",
      "Epoch 182/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4429 - accuracy: 0.8511\n",
      "Epoch 183/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4421 - accuracy: 0.8511\n",
      "Epoch 184/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4414 - accuracy: 0.8511\n",
      "Epoch 185/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4407 - accuracy: 0.8525\n",
      "Epoch 186/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4400 - accuracy: 0.8525\n",
      "Epoch 187/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4393 - accuracy: 0.8528\n",
      "Epoch 188/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4385 - accuracy: 0.8532\n",
      "Epoch 189/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4378 - accuracy: 0.8532\n",
      "Epoch 190/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4371 - accuracy: 0.8528\n",
      "Epoch 191/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4364 - accuracy: 0.8532\n",
      "Epoch 192/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4357 - accuracy: 0.8539\n",
      "Epoch 193/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4350 - accuracy: 0.8539\n",
      "Epoch 194/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4343 - accuracy: 0.8542\n",
      "Epoch 195/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4336 - accuracy: 0.8549\n",
      "Epoch 196/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4329 - accuracy: 0.8549\n",
      "Epoch 197/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4323 - accuracy: 0.8545\n",
      "Epoch 198/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4316 - accuracy: 0.8545\n",
      "Epoch 199/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4309 - accuracy: 0.8545\n",
      "Epoch 200/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4302 - accuracy: 0.8549\n",
      "Epoch 201/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4295 - accuracy: 0.8552\n",
      "Epoch 202/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4289 - accuracy: 0.8556\n",
      "Epoch 203/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4282 - accuracy: 0.8563\n",
      "Epoch 204/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8573\n",
      "Epoch 205/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4269 - accuracy: 0.8573\n",
      "Epoch 206/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4262 - accuracy: 0.8576\n",
      "Epoch 207/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4255 - accuracy: 0.8583\n",
      "Epoch 208/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4249 - accuracy: 0.8583\n",
      "Epoch 209/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4242 - accuracy: 0.8587\n",
      "Epoch 210/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4236 - accuracy: 0.8590\n",
      "Epoch 211/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4229 - accuracy: 0.8597\n",
      "Epoch 212/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4223 - accuracy: 0.8604\n",
      "Epoch 213/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8607\n",
      "Epoch 214/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.8607\n",
      "Epoch 215/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8611\n",
      "Epoch 216/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4197 - accuracy: 0.8614\n",
      "Epoch 217/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4191 - accuracy: 0.8618\n",
      "Epoch 218/400\n",
      "182/182 [==============================] - 2s 10ms/step - loss: 0.4185 - accuracy: 0.8614\n",
      "Epoch 219/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4179 - accuracy: 0.8621\n",
      "Epoch 220/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4172 - accuracy: 0.8628\n",
      "Epoch 221/400\n",
      "182/182 [==============================] - 2s 11ms/step - loss: 0.4166 - accuracy: 0.8631\n",
      "Epoch 222/400\n",
      "182/182 [==============================] - 2s 11ms/step - loss: 0.4160 - accuracy: 0.8628\n",
      "Epoch 223/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4154 - accuracy: 0.8638\n",
      "Epoch 224/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4148 - accuracy: 0.8638\n",
      "Epoch 225/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4142 - accuracy: 0.8649\n",
      "Epoch 226/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4135 - accuracy: 0.8649\n",
      "Epoch 227/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4129 - accuracy: 0.8652\n",
      "Epoch 228/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4123 - accuracy: 0.8659\n",
      "Epoch 229/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4117 - accuracy: 0.8666\n",
      "Epoch 230/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.4111 - accuracy: 0.8666\n",
      "Epoch 231/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4105 - accuracy: 0.8669\n",
      "Epoch 232/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4099 - accuracy: 0.8669\n",
      "Epoch 233/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4094 - accuracy: 0.8673\n",
      "Epoch 234/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4088 - accuracy: 0.8669\n",
      "Epoch 235/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4082 - accuracy: 0.8676\n",
      "Epoch 236/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4076 - accuracy: 0.8676\n",
      "Epoch 237/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4070 - accuracy: 0.8676\n",
      "Epoch 238/400\n",
      "182/182 [==============================] - 2s 11ms/step - loss: 0.4064 - accuracy: 0.8676\n",
      "Epoch 239/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4058 - accuracy: 0.8676\n",
      "Epoch 240/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4053 - accuracy: 0.8683\n",
      "Epoch 241/400\n",
      "182/182 [==============================] - 2s 10ms/step - loss: 0.4047 - accuracy: 0.8686\n",
      "Epoch 242/400\n",
      "182/182 [==============================] - 2s 10ms/step - loss: 0.4041 - accuracy: 0.8686\n",
      "Epoch 243/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4036 - accuracy: 0.8693\n",
      "Epoch 244/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4030 - accuracy: 0.8693\n",
      "Epoch 245/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4024 - accuracy: 0.8700\n",
      "Epoch 246/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4019 - accuracy: 0.8700\n",
      "Epoch 247/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4013 - accuracy: 0.8700\n",
      "Epoch 248/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4007 - accuracy: 0.8704\n",
      "Epoch 249/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4002 - accuracy: 0.8707\n",
      "Epoch 250/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3996 - accuracy: 0.8710\n",
      "Epoch 251/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3991 - accuracy: 0.8710\n",
      "Epoch 252/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3985 - accuracy: 0.8714\n",
      "Epoch 253/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3980 - accuracy: 0.8717\n",
      "Epoch 254/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.3974 - accuracy: 0.8721\n",
      "Epoch 255/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3969 - accuracy: 0.8721\n",
      "Epoch 256/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3963 - accuracy: 0.8724\n",
      "Epoch 257/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3958 - accuracy: 0.8728\n",
      "Epoch 258/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.3953 - accuracy: 0.8731\n",
      "Epoch 259/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3947 - accuracy: 0.8731\n",
      "Epoch 260/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3942 - accuracy: 0.8735\n",
      "Epoch 261/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3936 - accuracy: 0.8738\n",
      "Epoch 262/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3931 - accuracy: 0.8738\n",
      "Epoch 263/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3926 - accuracy: 0.8738\n",
      "Epoch 264/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3921 - accuracy: 0.8745\n",
      "Epoch 265/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3915 - accuracy: 0.8745\n",
      "Epoch 266/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3910 - accuracy: 0.8748\n",
      "Epoch 267/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3905 - accuracy: 0.8755\n",
      "Epoch 268/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3900 - accuracy: 0.8755\n",
      "Epoch 269/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3894 - accuracy: 0.8755\n",
      "Epoch 270/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3889 - accuracy: 0.8762\n",
      "Epoch 271/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3884 - accuracy: 0.8762\n",
      "Epoch 272/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3879 - accuracy: 0.8762\n",
      "Epoch 273/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3874 - accuracy: 0.8762\n",
      "Epoch 274/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3869 - accuracy: 0.8762\n",
      "Epoch 275/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3864 - accuracy: 0.8762\n",
      "Epoch 276/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3859 - accuracy: 0.8769\n",
      "Epoch 277/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3854 - accuracy: 0.8769\n",
      "Epoch 278/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3849 - accuracy: 0.8769\n",
      "Epoch 279/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3844 - accuracy: 0.8772\n",
      "Epoch 280/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3839 - accuracy: 0.8772\n",
      "Epoch 281/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3834 - accuracy: 0.8776\n",
      "Epoch 282/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3829 - accuracy: 0.8776\n",
      "Epoch 283/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3824 - accuracy: 0.8779\n",
      "Epoch 284/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3819 - accuracy: 0.8779\n",
      "Epoch 285/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3814 - accuracy: 0.8779\n",
      "Epoch 286/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3809 - accuracy: 0.8779\n",
      "Epoch 287/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3804 - accuracy: 0.8779\n",
      "Epoch 288/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3799 - accuracy: 0.8779\n",
      "Epoch 289/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3794 - accuracy: 0.8786\n",
      "Epoch 290/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3790 - accuracy: 0.8796\n",
      "Epoch 291/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3785 - accuracy: 0.8800\n",
      "Epoch 292/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3780 - accuracy: 0.8800\n",
      "Epoch 293/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3775 - accuracy: 0.8800\n",
      "Epoch 294/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3770 - accuracy: 0.8800\n",
      "Epoch 295/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3766 - accuracy: 0.8807\n",
      "Epoch 296/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3761 - accuracy: 0.8810\n",
      "Epoch 297/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3756 - accuracy: 0.8814\n",
      "Epoch 298/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3752 - accuracy: 0.8814\n",
      "Epoch 299/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3747 - accuracy: 0.8820\n",
      "Epoch 300/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3742 - accuracy: 0.8824\n",
      "Epoch 301/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3738 - accuracy: 0.8824\n",
      "Epoch 302/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3733 - accuracy: 0.8824\n",
      "Epoch 303/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3728 - accuracy: 0.8838\n",
      "Epoch 304/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3724 - accuracy: 0.8841\n",
      "Epoch 305/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3719 - accuracy: 0.8841\n",
      "Epoch 306/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3715 - accuracy: 0.8841\n",
      "Epoch 307/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3710 - accuracy: 0.8841\n",
      "Epoch 308/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3705 - accuracy: 0.8851\n",
      "Epoch 309/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3701 - accuracy: 0.8855\n",
      "Epoch 310/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3696 - accuracy: 0.8858\n",
      "Epoch 311/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3692 - accuracy: 0.8858\n",
      "Epoch 312/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3687 - accuracy: 0.8862\n",
      "Epoch 313/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3683 - accuracy: 0.8862\n",
      "Epoch 314/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3678 - accuracy: 0.8862\n",
      "Epoch 315/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3674 - accuracy: 0.8862\n",
      "Epoch 316/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3670 - accuracy: 0.8862\n",
      "Epoch 317/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3665 - accuracy: 0.8872\n",
      "Epoch 318/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3661 - accuracy: 0.8876\n",
      "Epoch 319/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3656 - accuracy: 0.8872\n",
      "Epoch 320/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3652 - accuracy: 0.8879\n",
      "Epoch 321/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3648 - accuracy: 0.8879\n",
      "Epoch 322/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3643 - accuracy: 0.8886\n",
      "Epoch 323/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3639 - accuracy: 0.8889\n",
      "Epoch 324/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3635 - accuracy: 0.8893\n",
      "Epoch 325/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3630 - accuracy: 0.8900\n",
      "Epoch 326/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3626 - accuracy: 0.8900\n",
      "Epoch 327/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3622 - accuracy: 0.8896\n",
      "Epoch 328/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3617 - accuracy: 0.8900\n",
      "Epoch 329/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3613 - accuracy: 0.8903\n",
      "Epoch 330/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3609 - accuracy: 0.8903\n",
      "Epoch 331/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3605 - accuracy: 0.8906\n",
      "Epoch 332/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3600 - accuracy: 0.8906\n",
      "Epoch 333/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3596 - accuracy: 0.8910\n",
      "Epoch 334/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3592 - accuracy: 0.8910\n",
      "Epoch 335/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3588 - accuracy: 0.8910\n",
      "Epoch 336/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3584 - accuracy: 0.8910\n",
      "Epoch 337/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3579 - accuracy: 0.8913\n",
      "Epoch 338/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3575 - accuracy: 0.8920\n",
      "Epoch 339/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3571 - accuracy: 0.8924\n",
      "Epoch 340/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3567 - accuracy: 0.8934\n",
      "Epoch 341/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3563 - accuracy: 0.8937\n",
      "Epoch 342/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3559 - accuracy: 0.8937\n",
      "Epoch 343/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3555 - accuracy: 0.8941\n",
      "Epoch 344/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3551 - accuracy: 0.8941\n",
      "Epoch 345/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3547 - accuracy: 0.8941\n",
      "Epoch 346/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3543 - accuracy: 0.8944\n",
      "Epoch 347/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3539 - accuracy: 0.8944\n",
      "Epoch 348/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3535 - accuracy: 0.8944\n",
      "Epoch 349/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3531 - accuracy: 0.8944\n",
      "Epoch 350/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3527 - accuracy: 0.8944\n",
      "Epoch 351/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3523 - accuracy: 0.8948\n",
      "Epoch 352/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3519 - accuracy: 0.8955\n",
      "Epoch 353/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3515 - accuracy: 0.8958\n",
      "Epoch 354/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3511 - accuracy: 0.8961\n",
      "Epoch 355/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3507 - accuracy: 0.8965\n",
      "Epoch 356/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3503 - accuracy: 0.8965\n",
      "Epoch 357/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3499 - accuracy: 0.8968\n",
      "Epoch 358/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3495 - accuracy: 0.8968\n",
      "Epoch 359/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3491 - accuracy: 0.8975\n",
      "Epoch 360/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3487 - accuracy: 0.8975\n",
      "Epoch 361/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3483 - accuracy: 0.8975\n",
      "Epoch 362/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3479 - accuracy: 0.8982\n",
      "Epoch 363/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3476 - accuracy: 0.8986\n",
      "Epoch 364/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3472 - accuracy: 0.8986\n",
      "Epoch 365/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3468 - accuracy: 0.8986\n",
      "Epoch 366/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3464 - accuracy: 0.8986\n",
      "Epoch 367/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3460 - accuracy: 0.8986\n",
      "Epoch 368/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3457 - accuracy: 0.8986\n",
      "Epoch 369/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3453 - accuracy: 0.8986\n",
      "Epoch 370/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3449 - accuracy: 0.8986\n",
      "Epoch 371/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3445 - accuracy: 0.8989\n",
      "Epoch 372/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3441 - accuracy: 0.8989\n",
      "Epoch 373/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3438 - accuracy: 0.8992\n",
      "Epoch 374/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3434 - accuracy: 0.8996\n",
      "Epoch 375/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3430 - accuracy: 0.8999\n",
      "Epoch 376/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3426 - accuracy: 0.9006\n",
      "Epoch 377/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3423 - accuracy: 0.9006\n",
      "Epoch 378/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3419 - accuracy: 0.9006\n",
      "Epoch 379/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3415 - accuracy: 0.9006\n",
      "Epoch 380/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3412 - accuracy: 0.9013\n",
      "Epoch 381/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3408 - accuracy: 0.9020\n",
      "Epoch 382/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3404 - accuracy: 0.9023\n",
      "Epoch 383/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3401 - accuracy: 0.9023\n",
      "Epoch 384/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3397 - accuracy: 0.9023\n",
      "Epoch 385/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3394 - accuracy: 0.9023\n",
      "Epoch 386/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3390 - accuracy: 0.9023\n",
      "Epoch 387/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3386 - accuracy: 0.9027\n",
      "Epoch 388/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3383 - accuracy: 0.9027\n",
      "Epoch 389/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3379 - accuracy: 0.9030\n",
      "Epoch 390/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3376 - accuracy: 0.9027\n",
      "Epoch 391/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3372 - accuracy: 0.9030\n",
      "Epoch 392/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3368 - accuracy: 0.9030\n",
      "Epoch 393/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3365 - accuracy: 0.9030\n",
      "Epoch 394/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3361 - accuracy: 0.9030\n",
      "Epoch 395/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3358 - accuracy: 0.9030\n",
      "Epoch 396/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3354 - accuracy: 0.9034\n",
      "Epoch 397/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3351 - accuracy: 0.9034\n",
      "Epoch 398/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3347 - accuracy: 0.9034\n",
      "Epoch 399/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3344 - accuracy: 0.9037\n",
      "Epoch 400/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3340 - accuracy: 0.9041\n"
     ]
    }
   ],
   "source": [
    "test = linear_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3316 - accuracy: 0.8876\n",
      "test\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 1.1909 - accuracy: 0.6405\n"
     ]
    }
   ],
   "source": [
    "linear_model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet\n",
      "\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "C1 (Conv2D)                  (None, 28, 28, 6)         456       \n",
      "_________________________________________________________________\n",
      "S2 (AveragePooling2D)        (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "C3 (Conv2D)                  (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "S4 (AveragePooling2D)        (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 1, 120)         48120     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "F6 (Dense)                   (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 5)                 425       \n",
      "=================================================================\n",
      "Total params: 61,581\n",
      "Trainable params: 61,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with open('config.json') as raw_config:\n",
    "    config = json.load(raw_config)\n",
    "\n",
    "lenet = LeNet(config)\n",
    "print(lenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0610 04:45:21.735181 140558240872256 training_utils.py:1436] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9058 - accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6187 - accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4273 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3019 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2184 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1627 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1250 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0980 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0777 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0620 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0500 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0410 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "lenet.train(overfit_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7064 - accuracy: 0.6000\n",
      "test\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1.6034 - accuracy: 0.5284\n"
     ]
    }
   ],
   "source": [
    "lenet.evaluate(overfit_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0610 04:45:41.921886 140558240872256 training_utils.py:1436] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "582/582 [==============================] - 8s 13ms/step - loss: 0.8887 - accuracy: 0.6668\n",
      "Epoch 2/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.7999 - accuracy: 0.6946\n",
      "Epoch 3/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.7358 - accuracy: 0.7184\n",
      "Epoch 4/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.6675 - accuracy: 0.7497\n",
      "Epoch 5/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.5913 - accuracy: 0.7854\n",
      "Epoch 6/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.5139 - accuracy: 0.8191\n",
      "Epoch 7/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.4369 - accuracy: 0.8477\n",
      "Epoch 8/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.3630 - accuracy: 0.8831\n",
      "Epoch 9/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.3007 - accuracy: 0.9075\n",
      "Epoch 10/400\n",
      "582/582 [==============================] - 7s 12ms/step - loss: 0.2339 - accuracy: 0.9302\n",
      "Epoch 11/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.1861 - accuracy: 0.9519\n",
      "Epoch 12/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.1529 - accuracy: 0.9587\n",
      "Epoch 13/400\n",
      "582/582 [==============================] - 7s 12ms/step - loss: 0.1153 - accuracy: 0.9708\n",
      "Epoch 14/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.0795 - accuracy: 0.9876\n",
      "Epoch 15/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.0713 - accuracy: 0.9856\n",
      "Epoch 16/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.0745 - accuracy: 0.9794\n",
      "Epoch 17/400\n",
      "582/582 [==============================] - 7s 12ms/step - loss: 0.0641 - accuracy: 0.9825\n",
      "Epoch 18/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.0513 - accuracy: 0.9869\n",
      "Epoch 19/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.0726 - accuracy: 0.9770\n",
      "Epoch 20/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.0302 - accuracy: 0.9935\n",
      "Epoch 21/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.0178 - accuracy: 0.9986\n",
      "Epoch 22/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.0873 - accuracy: 0.9691\n",
      "Epoch 23/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.0767 - accuracy: 0.9770\n",
      "Epoch 24/400\n",
      "197/582 [=========>....................] - ETA: 4s - loss: 0.0297 - accuracy: 0.9919"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-e0ca6a083b69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/image-classification/models.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, overfit_mode)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverfit_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverfit_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3508\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3510\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    571\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test = lenet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
