{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone -b gpu https://github.com/shpotes/image-classification/\n",
    "%cd image-classification\n",
    "!pip install -q -r requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from dataset import *\n",
    "from utils import * \n",
    "\n",
    "from models import LinearModel, LeNet\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json') as raw_config:\n",
    "    config = json.load(raw_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data/train/b479226f08344398b688dcc6f929c330.jpg', 1),\n",
       " ('data/train/2104059e4add482e9c09035b5a70ae4f.jpg', 1),\n",
       " ('data/train/a394bd69f5554852ab6816860ff5f6d4.jpg', 3),\n",
       " ('data/train/5f6afd93004a43018a51565dd4d89958.jpg', 3),\n",
       " ('data/train/832805b9bda445e78b4a0c2675f625e5.jpg', 3)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_source = build_source_from_metadata(pd.read_csv(config['model']['metadata_path']),\n",
    "                                        config['model']['data_path'], 'train')\n",
    "train_source[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img, label, model=None, size=(32, 32)):\n",
    "    img = tf.image.resize(img, size=size)\n",
    "    img = img / 255.0\n",
    "    return img, label\n",
    "\n",
    "dataset = make_dataset(train_source, preprocess_image, training=True, batch_size=3,\n",
    "                       num_epochs=1, num_parallel_calls=4)\n",
    "dataset = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=53, shape=(3,), dtype=int32, numpy=array([1, 1, 3], dtype=int32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dataset)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow_batch_of_three(next(dataset), config['model']['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModel\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 15365     \n",
      "=================================================================\n",
      "Total params: 15,365\n",
      "Trainable params: 15,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "linear_model = LinearModel(config)\n",
    "print(linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0610 03:53:47.524817 140243699922752 training_utils.py:1436] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 0.5633 - accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3474 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2875 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3172 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3121 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2892 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2577 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2268 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2031 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1891 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1837 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1824 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1802 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1740 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1639 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1520 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1408 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1315 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1245 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "test = linear_model.train(overfit_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0610 03:54:29.713122 140243699922752 training_utils.py:1436] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "182/182 [==============================] - 2s 12ms/step - loss: 0.7139 - accuracy: 0.7366\n",
      "Epoch 2/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6960 - accuracy: 0.7431\n",
      "Epoch 3/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6926 - accuracy: 0.7452\n",
      "Epoch 4/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6893 - accuracy: 0.7472\n",
      "Epoch 5/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6862 - accuracy: 0.7486\n",
      "Epoch 6/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.6832 - accuracy: 0.7490\n",
      "Epoch 7/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.6802 - accuracy: 0.7514\n",
      "Epoch 8/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6774 - accuracy: 0.7517\n",
      "Epoch 9/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.6745 - accuracy: 0.7528\n",
      "Epoch 10/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.6718 - accuracy: 0.7538\n",
      "Epoch 11/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.6691 - accuracy: 0.7555\n",
      "Epoch 12/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6664 - accuracy: 0.7569\n",
      "Epoch 13/400\n",
      "182/182 [==============================] - 2s 11ms/step - loss: 0.6637 - accuracy: 0.7583\n",
      "Epoch 14/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6612 - accuracy: 0.7593\n",
      "Epoch 15/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.6586 - accuracy: 0.7603\n",
      "Epoch 16/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.6561 - accuracy: 0.7603\n",
      "Epoch 17/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6536 - accuracy: 0.7610\n",
      "Epoch 18/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6512 - accuracy: 0.7620\n",
      "Epoch 19/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6488 - accuracy: 0.7638\n",
      "Epoch 20/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6464 - accuracy: 0.7651\n",
      "Epoch 21/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6441 - accuracy: 0.7669\n",
      "Epoch 22/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6418 - accuracy: 0.7672\n",
      "Epoch 23/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6395 - accuracy: 0.7686\n",
      "Epoch 24/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6373 - accuracy: 0.7703\n",
      "Epoch 25/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6350 - accuracy: 0.7713\n",
      "Epoch 26/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6329 - accuracy: 0.7730\n",
      "Epoch 27/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6307 - accuracy: 0.7741\n",
      "Epoch 28/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6286 - accuracy: 0.7758\n",
      "Epoch 29/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6264 - accuracy: 0.7768\n",
      "Epoch 30/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6244 - accuracy: 0.7782\n",
      "Epoch 31/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6223 - accuracy: 0.7789\n",
      "Epoch 32/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.6203 - accuracy: 0.7792\n",
      "Epoch 33/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.6182 - accuracy: 0.7806\n",
      "Epoch 34/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6162 - accuracy: 0.7806\n",
      "Epoch 35/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6143 - accuracy: 0.7806\n",
      "Epoch 36/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6123 - accuracy: 0.7809\n",
      "Epoch 37/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6104 - accuracy: 0.7816\n",
      "Epoch 38/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6085 - accuracy: 0.7827\n",
      "Epoch 39/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.6066 - accuracy: 0.7844\n",
      "Epoch 40/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6047 - accuracy: 0.7858\n",
      "Epoch 41/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6029 - accuracy: 0.7858\n",
      "Epoch 42/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6010 - accuracy: 0.7865\n",
      "Epoch 43/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5992 - accuracy: 0.7868\n",
      "Epoch 44/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5974 - accuracy: 0.7871\n",
      "Epoch 45/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5956 - accuracy: 0.7882\n",
      "Epoch 46/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5939 - accuracy: 0.7889\n",
      "Epoch 47/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5921 - accuracy: 0.7895\n",
      "Epoch 48/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5904 - accuracy: 0.7906\n",
      "Epoch 49/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5887 - accuracy: 0.7920\n",
      "Epoch 50/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5870 - accuracy: 0.7923\n",
      "Epoch 51/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5853 - accuracy: 0.7933\n",
      "Epoch 52/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.5837 - accuracy: 0.7940\n",
      "Epoch 53/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.5820 - accuracy: 0.7947\n",
      "Epoch 54/400\n",
      "182/182 [==============================] - 2s 11ms/step - loss: 0.5804 - accuracy: 0.7950\n",
      "Epoch 55/400\n",
      "182/182 [==============================] - 2s 11ms/step - loss: 0.5788 - accuracy: 0.7950\n",
      "Epoch 56/400\n",
      "182/182 [==============================] - 2s 10ms/step - loss: 0.5772 - accuracy: 0.7964\n",
      "Epoch 57/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.5756 - accuracy: 0.7971\n",
      "Epoch 58/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5740 - accuracy: 0.7981\n",
      "Epoch 59/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5724 - accuracy: 0.7985\n",
      "Epoch 60/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.5709 - accuracy: 0.7988\n",
      "Epoch 61/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5693 - accuracy: 0.7988\n",
      "Epoch 62/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.5678 - accuracy: 0.7995\n",
      "Epoch 63/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.5663 - accuracy: 0.8002\n",
      "Epoch 64/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5648 - accuracy: 0.8009\n",
      "Epoch 65/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5633 - accuracy: 0.8016\n",
      "Epoch 66/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5618 - accuracy: 0.8016\n",
      "Epoch 67/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5604 - accuracy: 0.8016\n",
      "Epoch 68/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5589 - accuracy: 0.8026\n",
      "Epoch 69/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5575 - accuracy: 0.8033\n",
      "Epoch 70/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5560 - accuracy: 0.8033\n",
      "Epoch 71/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5546 - accuracy: 0.8043\n",
      "Epoch 72/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5532 - accuracy: 0.8050\n",
      "Epoch 73/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5518 - accuracy: 0.8054\n",
      "Epoch 74/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5504 - accuracy: 0.8061\n",
      "Epoch 75/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5491 - accuracy: 0.8074\n",
      "Epoch 76/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5477 - accuracy: 0.8074\n",
      "Epoch 77/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5463 - accuracy: 0.8085\n",
      "Epoch 78/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5450 - accuracy: 0.8091\n",
      "Epoch 79/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5437 - accuracy: 0.8091\n",
      "Epoch 80/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5423 - accuracy: 0.8091\n",
      "Epoch 81/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.5410 - accuracy: 0.8091\n",
      "Epoch 82/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5397 - accuracy: 0.8095\n",
      "Epoch 83/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5384 - accuracy: 0.8102\n",
      "Epoch 84/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5371 - accuracy: 0.8105\n",
      "Epoch 85/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5359 - accuracy: 0.8119\n",
      "Epoch 86/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5346 - accuracy: 0.8119\n",
      "Epoch 87/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5333 - accuracy: 0.8126\n",
      "Epoch 88/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5321 - accuracy: 0.8133\n",
      "Epoch 89/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5308 - accuracy: 0.8140\n",
      "Epoch 90/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5296 - accuracy: 0.8150\n",
      "Epoch 91/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5284 - accuracy: 0.8150\n",
      "Epoch 92/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5272 - accuracy: 0.8150\n",
      "Epoch 93/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5260 - accuracy: 0.8153\n",
      "Epoch 94/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5248 - accuracy: 0.8153\n",
      "Epoch 95/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5236 - accuracy: 0.8157\n",
      "Epoch 96/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5224 - accuracy: 0.8157\n",
      "Epoch 97/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5212 - accuracy: 0.8160\n",
      "Epoch 98/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5200 - accuracy: 0.8160\n",
      "Epoch 99/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5189 - accuracy: 0.8167\n",
      "Epoch 100/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5177 - accuracy: 0.8171\n",
      "Epoch 101/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5166 - accuracy: 0.8177\n",
      "Epoch 102/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5154 - accuracy: 0.8184\n",
      "Epoch 103/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5143 - accuracy: 0.8188\n",
      "Epoch 104/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5132 - accuracy: 0.8191\n",
      "Epoch 105/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5121 - accuracy: 0.8191\n",
      "Epoch 106/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5110 - accuracy: 0.8198\n",
      "Epoch 107/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5099 - accuracy: 0.8212\n",
      "Epoch 108/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5088 - accuracy: 0.8222\n",
      "Epoch 109/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5077 - accuracy: 0.8232\n",
      "Epoch 110/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5066 - accuracy: 0.8243\n",
      "Epoch 111/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5055 - accuracy: 0.8246\n",
      "Epoch 112/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5045 - accuracy: 0.8253\n",
      "Epoch 113/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5034 - accuracy: 0.8257\n",
      "Epoch 114/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5023 - accuracy: 0.8263\n",
      "Epoch 115/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5013 - accuracy: 0.8267\n",
      "Epoch 116/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5003 - accuracy: 0.8270\n",
      "Epoch 117/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4992 - accuracy: 0.8274\n",
      "Epoch 118/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4982 - accuracy: 0.8277\n",
      "Epoch 119/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4972 - accuracy: 0.8281\n",
      "Epoch 120/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4962 - accuracy: 0.8291\n",
      "Epoch 121/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4951 - accuracy: 0.8294\n",
      "Epoch 122/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4941 - accuracy: 0.8301\n",
      "Epoch 123/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4931 - accuracy: 0.8301\n",
      "Epoch 124/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4921 - accuracy: 0.8301\n",
      "Epoch 125/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4912 - accuracy: 0.8301\n",
      "Epoch 126/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4902 - accuracy: 0.8305\n",
      "Epoch 127/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4892 - accuracy: 0.8305\n",
      "Epoch 128/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4882 - accuracy: 0.8308\n",
      "Epoch 129/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4873 - accuracy: 0.8312\n",
      "Epoch 130/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4863 - accuracy: 0.8315\n",
      "Epoch 131/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4854 - accuracy: 0.8332\n",
      "Epoch 132/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4844 - accuracy: 0.8332\n",
      "Epoch 133/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4835 - accuracy: 0.8336\n",
      "Epoch 134/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4825 - accuracy: 0.8343\n",
      "Epoch 135/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4816 - accuracy: 0.8343\n",
      "Epoch 136/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4807 - accuracy: 0.8343\n",
      "Epoch 137/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4797 - accuracy: 0.8343\n",
      "Epoch 138/400\n",
      "182/182 [==============================] - 2s 10ms/step - loss: 0.4788 - accuracy: 0.8339\n",
      "Epoch 139/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4779 - accuracy: 0.8339\n",
      "Epoch 140/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4770 - accuracy: 0.8339\n",
      "Epoch 141/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4761 - accuracy: 0.8343\n",
      "Epoch 142/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4752 - accuracy: 0.8343\n",
      "Epoch 143/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4743 - accuracy: 0.8343\n",
      "Epoch 144/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4734 - accuracy: 0.8349\n",
      "Epoch 145/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4726 - accuracy: 0.8353\n",
      "Epoch 146/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4717 - accuracy: 0.8353\n",
      "Epoch 147/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.4708 - accuracy: 0.8356\n",
      "Epoch 148/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.4699 - accuracy: 0.8360\n",
      "Epoch 149/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4691 - accuracy: 0.8360\n",
      "Epoch 150/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4682 - accuracy: 0.8363\n",
      "Epoch 151/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4674 - accuracy: 0.8367\n",
      "Epoch 152/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4665 - accuracy: 0.8367\n",
      "Epoch 153/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4657 - accuracy: 0.8377\n",
      "Epoch 154/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4648 - accuracy: 0.8384\n",
      "Epoch 155/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.4640 - accuracy: 0.8391\n",
      "Epoch 156/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.4631 - accuracy: 0.8391\n",
      "Epoch 157/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4623 - accuracy: 0.8404\n",
      "Epoch 158/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4615 - accuracy: 0.8404\n",
      "Epoch 159/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4607 - accuracy: 0.8404\n",
      "Epoch 160/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4599 - accuracy: 0.8408\n",
      "Epoch 161/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4590 - accuracy: 0.8411\n",
      "Epoch 162/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4582 - accuracy: 0.8411\n",
      "Epoch 163/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4574 - accuracy: 0.8411\n",
      "Epoch 164/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4566 - accuracy: 0.8422\n",
      "Epoch 165/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4558 - accuracy: 0.8422\n",
      "Epoch 166/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4550 - accuracy: 0.8432\n",
      "Epoch 167/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4543 - accuracy: 0.8435\n",
      "Epoch 168/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4535 - accuracy: 0.8442\n",
      "Epoch 169/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4527 - accuracy: 0.8446\n",
      "Epoch 170/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4519 - accuracy: 0.8453\n",
      "Epoch 171/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4511 - accuracy: 0.8459\n",
      "Epoch 172/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4504 - accuracy: 0.8463\n",
      "Epoch 173/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4496 - accuracy: 0.8463\n",
      "Epoch 174/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4488 - accuracy: 0.8473\n",
      "Epoch 175/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4481 - accuracy: 0.8480\n",
      "Epoch 176/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4473 - accuracy: 0.8490\n",
      "Epoch 177/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4466 - accuracy: 0.8497\n",
      "Epoch 178/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4458 - accuracy: 0.8501\n",
      "Epoch 179/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4451 - accuracy: 0.8504\n",
      "Epoch 180/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4443 - accuracy: 0.8504\n",
      "Epoch 181/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4436 - accuracy: 0.8508\n",
      "Epoch 182/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4429 - accuracy: 0.8511\n",
      "Epoch 183/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4421 - accuracy: 0.8511\n",
      "Epoch 184/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4414 - accuracy: 0.8511\n",
      "Epoch 185/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4407 - accuracy: 0.8525\n",
      "Epoch 186/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4400 - accuracy: 0.8525\n",
      "Epoch 187/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4393 - accuracy: 0.8528\n",
      "Epoch 188/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4385 - accuracy: 0.8532\n",
      "Epoch 189/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4378 - accuracy: 0.8532\n",
      "Epoch 190/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4371 - accuracy: 0.8528\n",
      "Epoch 191/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4364 - accuracy: 0.8532\n",
      "Epoch 192/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4357 - accuracy: 0.8539\n",
      "Epoch 193/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4350 - accuracy: 0.8539\n",
      "Epoch 194/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4343 - accuracy: 0.8542\n",
      "Epoch 195/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4336 - accuracy: 0.8549\n",
      "Epoch 196/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4329 - accuracy: 0.8549\n",
      "Epoch 197/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4323 - accuracy: 0.8545\n",
      "Epoch 198/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4316 - accuracy: 0.8545\n",
      "Epoch 199/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4309 - accuracy: 0.8545\n",
      "Epoch 200/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4302 - accuracy: 0.8549\n",
      "Epoch 201/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4295 - accuracy: 0.8552\n",
      "Epoch 202/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4289 - accuracy: 0.8556\n",
      "Epoch 203/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4282 - accuracy: 0.8563\n",
      "Epoch 204/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8573\n",
      "Epoch 205/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4269 - accuracy: 0.8573\n",
      "Epoch 206/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4262 - accuracy: 0.8576\n",
      "Epoch 207/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4255 - accuracy: 0.8583\n",
      "Epoch 208/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4249 - accuracy: 0.8583\n",
      "Epoch 209/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4242 - accuracy: 0.8587\n",
      "Epoch 210/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4236 - accuracy: 0.8590\n",
      "Epoch 211/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4229 - accuracy: 0.8597\n",
      "Epoch 212/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4223 - accuracy: 0.8604\n",
      "Epoch 213/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8607\n",
      "Epoch 214/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.8607\n",
      "Epoch 215/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8611\n",
      "Epoch 216/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4197 - accuracy: 0.8614\n",
      "Epoch 217/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4191 - accuracy: 0.8618\n",
      "Epoch 218/400\n",
      "182/182 [==============================] - 2s 10ms/step - loss: 0.4185 - accuracy: 0.8614\n",
      "Epoch 219/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4179 - accuracy: 0.8621\n",
      "Epoch 220/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4172 - accuracy: 0.8628\n",
      "Epoch 221/400\n",
      "182/182 [==============================] - 2s 11ms/step - loss: 0.4166 - accuracy: 0.8631\n",
      "Epoch 222/400\n",
      "182/182 [==============================] - 2s 11ms/step - loss: 0.4160 - accuracy: 0.8628\n",
      "Epoch 223/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4154 - accuracy: 0.8638\n",
      "Epoch 224/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4148 - accuracy: 0.8638\n",
      "Epoch 225/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4142 - accuracy: 0.8649\n",
      "Epoch 226/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4135 - accuracy: 0.8649\n",
      "Epoch 227/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4129 - accuracy: 0.8652\n",
      "Epoch 228/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4123 - accuracy: 0.8659\n",
      "Epoch 229/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4117 - accuracy: 0.8666\n",
      "Epoch 230/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.4111 - accuracy: 0.8666\n",
      "Epoch 231/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4105 - accuracy: 0.8669\n",
      "Epoch 232/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4099 - accuracy: 0.8669\n",
      "Epoch 233/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4094 - accuracy: 0.8673\n",
      "Epoch 234/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4088 - accuracy: 0.8669\n",
      "Epoch 235/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4082 - accuracy: 0.8676\n",
      "Epoch 236/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4076 - accuracy: 0.8676\n",
      "Epoch 237/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4070 - accuracy: 0.8676\n",
      "Epoch 238/400\n",
      "182/182 [==============================] - 2s 11ms/step - loss: 0.4064 - accuracy: 0.8676\n",
      "Epoch 239/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4058 - accuracy: 0.8676\n",
      "Epoch 240/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4053 - accuracy: 0.8683\n",
      "Epoch 241/400\n",
      "182/182 [==============================] - 2s 10ms/step - loss: 0.4047 - accuracy: 0.8686\n",
      "Epoch 242/400\n",
      "182/182 [==============================] - 2s 10ms/step - loss: 0.4041 - accuracy: 0.8686\n",
      "Epoch 243/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4036 - accuracy: 0.8693\n",
      "Epoch 244/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4030 - accuracy: 0.8693\n",
      "Epoch 245/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4024 - accuracy: 0.8700\n",
      "Epoch 246/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4019 - accuracy: 0.8700\n",
      "Epoch 247/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4013 - accuracy: 0.8700\n",
      "Epoch 248/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4007 - accuracy: 0.8704\n",
      "Epoch 249/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4002 - accuracy: 0.8707\n",
      "Epoch 250/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3996 - accuracy: 0.8710\n",
      "Epoch 251/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3991 - accuracy: 0.8710\n",
      "Epoch 252/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3985 - accuracy: 0.8714\n",
      "Epoch 253/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3980 - accuracy: 0.8717\n",
      "Epoch 254/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.3974 - accuracy: 0.8721\n",
      "Epoch 255/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3969 - accuracy: 0.8721\n",
      "Epoch 256/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3963 - accuracy: 0.8724\n",
      "Epoch 257/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3958 - accuracy: 0.8728\n",
      "Epoch 258/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.3953 - accuracy: 0.8731\n",
      "Epoch 259/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3947 - accuracy: 0.8731\n",
      "Epoch 260/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3942 - accuracy: 0.8735\n",
      "Epoch 261/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3936 - accuracy: 0.8738\n",
      "Epoch 262/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3931 - accuracy: 0.8738\n",
      "Epoch 263/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3926 - accuracy: 0.8738\n",
      "Epoch 264/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3921 - accuracy: 0.8745\n",
      "Epoch 265/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3915 - accuracy: 0.8745\n",
      "Epoch 266/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3910 - accuracy: 0.8748\n",
      "Epoch 267/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3905 - accuracy: 0.8755\n",
      "Epoch 268/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3900 - accuracy: 0.8755\n",
      "Epoch 269/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3894 - accuracy: 0.8755\n",
      "Epoch 270/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3889 - accuracy: 0.8762\n",
      "Epoch 271/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3884 - accuracy: 0.8762\n",
      "Epoch 272/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3879 - accuracy: 0.8762\n",
      "Epoch 273/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3874 - accuracy: 0.8762\n",
      "Epoch 274/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3869 - accuracy: 0.8762\n",
      "Epoch 275/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3864 - accuracy: 0.8762\n",
      "Epoch 276/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3859 - accuracy: 0.8769\n",
      "Epoch 277/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3854 - accuracy: 0.8769\n",
      "Epoch 278/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3849 - accuracy: 0.8769\n",
      "Epoch 279/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3844 - accuracy: 0.8772\n",
      "Epoch 280/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3839 - accuracy: 0.8772\n",
      "Epoch 281/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3834 - accuracy: 0.8776\n",
      "Epoch 282/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3829 - accuracy: 0.8776\n",
      "Epoch 283/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3824 - accuracy: 0.8779\n",
      "Epoch 284/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3819 - accuracy: 0.8779\n",
      "Epoch 285/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3814 - accuracy: 0.8779\n",
      "Epoch 286/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3809 - accuracy: 0.8779\n",
      "Epoch 287/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3804 - accuracy: 0.8779\n",
      "Epoch 288/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3799 - accuracy: 0.8779\n",
      "Epoch 289/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3794 - accuracy: 0.8786\n",
      "Epoch 290/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3790 - accuracy: 0.8796\n",
      "Epoch 291/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3785 - accuracy: 0.8800\n",
      "Epoch 292/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3780 - accuracy: 0.8800\n",
      "Epoch 293/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3775 - accuracy: 0.8800\n",
      "Epoch 294/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3770 - accuracy: 0.8800\n",
      "Epoch 295/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3766 - accuracy: 0.8807\n",
      "Epoch 296/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3761 - accuracy: 0.8810\n",
      "Epoch 297/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3756 - accuracy: 0.8814\n",
      "Epoch 298/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3752 - accuracy: 0.8814\n",
      "Epoch 299/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3747 - accuracy: 0.8820\n",
      "Epoch 300/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3742 - accuracy: 0.8824\n",
      "Epoch 301/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3738 - accuracy: 0.8824\n",
      "Epoch 302/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3733 - accuracy: 0.8824\n",
      "Epoch 303/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3728 - accuracy: 0.8838\n",
      "Epoch 304/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3724 - accuracy: 0.8841\n",
      "Epoch 305/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3719 - accuracy: 0.8841\n",
      "Epoch 306/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3715 - accuracy: 0.8841\n",
      "Epoch 307/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3710 - accuracy: 0.8841\n",
      "Epoch 308/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3705 - accuracy: 0.8851\n",
      "Epoch 309/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3701 - accuracy: 0.8855\n",
      "Epoch 310/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3696 - accuracy: 0.8858\n",
      "Epoch 311/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3692 - accuracy: 0.8858\n",
      "Epoch 312/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3687 - accuracy: 0.8862\n",
      "Epoch 313/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3683 - accuracy: 0.8862\n",
      "Epoch 314/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3678 - accuracy: 0.8862\n",
      "Epoch 315/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3674 - accuracy: 0.8862\n",
      "Epoch 316/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3670 - accuracy: 0.8862\n",
      "Epoch 317/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3665 - accuracy: 0.8872\n",
      "Epoch 318/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3661 - accuracy: 0.8876\n",
      "Epoch 319/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3656 - accuracy: 0.8872\n",
      "Epoch 320/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3652 - accuracy: 0.8879\n",
      "Epoch 321/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3648 - accuracy: 0.8879\n",
      "Epoch 322/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3643 - accuracy: 0.8886\n",
      "Epoch 323/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3639 - accuracy: 0.8889\n",
      "Epoch 324/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3635 - accuracy: 0.8893\n",
      "Epoch 325/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3630 - accuracy: 0.8900\n",
      "Epoch 326/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3626 - accuracy: 0.8900\n",
      "Epoch 327/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3622 - accuracy: 0.8896\n",
      "Epoch 328/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3617 - accuracy: 0.8900\n",
      "Epoch 329/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3613 - accuracy: 0.8903\n",
      "Epoch 330/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3609 - accuracy: 0.8903\n",
      "Epoch 331/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3605 - accuracy: 0.8906\n",
      "Epoch 332/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3600 - accuracy: 0.8906\n",
      "Epoch 333/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3596 - accuracy: 0.8910\n",
      "Epoch 334/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3592 - accuracy: 0.8910\n",
      "Epoch 335/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3588 - accuracy: 0.8910\n",
      "Epoch 336/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3584 - accuracy: 0.8910\n",
      "Epoch 337/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3579 - accuracy: 0.8913\n",
      "Epoch 338/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3575 - accuracy: 0.8920\n",
      "Epoch 339/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3571 - accuracy: 0.8924\n",
      "Epoch 340/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3567 - accuracy: 0.8934\n",
      "Epoch 341/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3563 - accuracy: 0.8937\n",
      "Epoch 342/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3559 - accuracy: 0.8937\n",
      "Epoch 343/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3555 - accuracy: 0.8941\n",
      "Epoch 344/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3551 - accuracy: 0.8941\n",
      "Epoch 345/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3547 - accuracy: 0.8941\n",
      "Epoch 346/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3543 - accuracy: 0.8944\n",
      "Epoch 347/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3539 - accuracy: 0.8944\n",
      "Epoch 348/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3535 - accuracy: 0.8944\n",
      "Epoch 349/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3531 - accuracy: 0.8944\n",
      "Epoch 350/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3527 - accuracy: 0.8944\n",
      "Epoch 351/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3523 - accuracy: 0.8948\n",
      "Epoch 352/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3519 - accuracy: 0.8955\n",
      "Epoch 353/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3515 - accuracy: 0.8958\n",
      "Epoch 354/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3511 - accuracy: 0.8961\n",
      "Epoch 355/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3507 - accuracy: 0.8965\n",
      "Epoch 356/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3503 - accuracy: 0.8965\n",
      "Epoch 357/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3499 - accuracy: 0.8968\n",
      "Epoch 358/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3495 - accuracy: 0.8968\n",
      "Epoch 359/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3491 - accuracy: 0.8975\n",
      "Epoch 360/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3487 - accuracy: 0.8975\n",
      "Epoch 361/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3483 - accuracy: 0.8975\n",
      "Epoch 362/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3479 - accuracy: 0.8982\n",
      "Epoch 363/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3476 - accuracy: 0.8986\n",
      "Epoch 364/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3472 - accuracy: 0.8986\n",
      "Epoch 365/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3468 - accuracy: 0.8986\n",
      "Epoch 366/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3464 - accuracy: 0.8986\n",
      "Epoch 367/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3460 - accuracy: 0.8986\n",
      "Epoch 368/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3457 - accuracy: 0.8986\n",
      "Epoch 369/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3453 - accuracy: 0.8986\n",
      "Epoch 370/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3449 - accuracy: 0.8986\n",
      "Epoch 371/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3445 - accuracy: 0.8989\n",
      "Epoch 372/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3441 - accuracy: 0.8989\n",
      "Epoch 373/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3438 - accuracy: 0.8992\n",
      "Epoch 374/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3434 - accuracy: 0.8996\n",
      "Epoch 375/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3430 - accuracy: 0.8999\n",
      "Epoch 376/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3426 - accuracy: 0.9006\n",
      "Epoch 377/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3423 - accuracy: 0.9006\n",
      "Epoch 378/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3419 - accuracy: 0.9006\n",
      "Epoch 379/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3415 - accuracy: 0.9006\n",
      "Epoch 380/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3412 - accuracy: 0.9013\n",
      "Epoch 381/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3408 - accuracy: 0.9020\n",
      "Epoch 382/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3404 - accuracy: 0.9023\n",
      "Epoch 383/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3401 - accuracy: 0.9023\n",
      "Epoch 384/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3397 - accuracy: 0.9023\n",
      "Epoch 385/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3394 - accuracy: 0.9023\n",
      "Epoch 386/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3390 - accuracy: 0.9023\n",
      "Epoch 387/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3386 - accuracy: 0.9027\n",
      "Epoch 388/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3383 - accuracy: 0.9027\n",
      "Epoch 389/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3379 - accuracy: 0.9030\n",
      "Epoch 390/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3376 - accuracy: 0.9027\n",
      "Epoch 391/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3372 - accuracy: 0.9030\n",
      "Epoch 392/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3368 - accuracy: 0.9030\n",
      "Epoch 393/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3365 - accuracy: 0.9030\n",
      "Epoch 394/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3361 - accuracy: 0.9030\n",
      "Epoch 395/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3358 - accuracy: 0.9030\n",
      "Epoch 396/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3354 - accuracy: 0.9034\n",
      "Epoch 397/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3351 - accuracy: 0.9034\n",
      "Epoch 398/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3347 - accuracy: 0.9034\n",
      "Epoch 399/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3344 - accuracy: 0.9037\n",
      "Epoch 400/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3340 - accuracy: 0.9041\n"
     ]
    }
   ],
   "source": [
    "test = linear_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3316 - accuracy: 0.8876\n",
      "test\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 1.1909 - accuracy: 0.6405\n"
     ]
    }
   ],
   "source": [
    "linear_model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet\n",
      "\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "C1 (Conv2D)                  (None, 28, 28, 6)         456       \n",
      "_________________________________________________________________\n",
      "S2 (AveragePooling2D)        (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "C3 (Conv2D)                  (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "S4 (AveragePooling2D)        (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 1, 120)         48120     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "F6 (Dense)                   (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 5)                 425       \n",
      "=================================================================\n",
      "Total params: 61,581\n",
      "Trainable params: 61,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with open('config.json') as raw_config:\n",
    "    config = json.load(raw_config)\n",
    "\n",
    "lenet = LeNet(config)\n",
    "print(lenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0610 04:45:21.735181 140558240872256 training_utils.py:1436] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9058 - accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6187 - accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4273 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3019 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2184 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1627 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1250 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0980 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0777 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0620 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0500 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0410 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "lenet.train(overfit_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7064 - accuracy: 0.6000\n",
      "test\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1.6034 - accuracy: 0.5284\n"
     ]
    }
   ],
   "source": [
    "lenet.evaluate(overfit_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0610 04:45:41.921886 140558240872256 training_utils.py:1436] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "582/582 [==============================] - 8s 13ms/step - loss: 0.8887 - accuracy: 0.6668\n",
      "Epoch 2/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.7999 - accuracy: 0.6946\n",
      "Epoch 3/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.7358 - accuracy: 0.7184\n",
      "Epoch 4/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.6675 - accuracy: 0.7497\n",
      "Epoch 5/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.5913 - accuracy: 0.7854\n",
      "Epoch 6/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.5139 - accuracy: 0.8191\n",
      "Epoch 7/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.4369 - accuracy: 0.8477\n",
      "Epoch 8/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.3630 - accuracy: 0.8831\n",
      "Epoch 9/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.3007 - accuracy: 0.9075\n",
      "Epoch 10/400\n",
      "582/582 [==============================] - 7s 12ms/step - loss: 0.2339 - accuracy: 0.9302\n",
      "Epoch 11/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.1861 - accuracy: 0.9519\n",
      "Epoch 12/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.1529 - accuracy: 0.9587\n",
      "Epoch 13/400\n",
      "582/582 [==============================] - 7s 12ms/step - loss: 0.1153 - accuracy: 0.9708\n",
      "Epoch 14/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.0795 - accuracy: 0.9876\n",
      "Epoch 15/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.0713 - accuracy: 0.9856\n",
      "Epoch 16/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.0745 - accuracy: 0.9794\n",
      "Epoch 17/400\n",
      "582/582 [==============================] - 7s 12ms/step - loss: 0.0641 - accuracy: 0.9825\n",
      "Epoch 18/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.0513 - accuracy: 0.9869\n",
      "Epoch 19/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.0726 - accuracy: 0.9770\n",
      "Epoch 20/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.0302 - accuracy: 0.9935\n",
      "Epoch 21/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.0178 - accuracy: 0.9986\n",
      "Epoch 22/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.0873 - accuracy: 0.9691\n",
      "Epoch 23/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.0767 - accuracy: 0.9770\n",
      "Epoch 24/400\n",
      "197/582 [=========>....................] - ETA: 4s - loss: 0.0297 - accuracy: 0.9919"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-e0ca6a083b69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/image-classification/models.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, overfit_mode)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverfit_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverfit_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3508\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3510\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    571\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test = lenet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
