{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone -b gpu https://github.com/shpotes/image-classification/\n",
    "%cd image-classification\n",
    "!pip install -q tensorflow==2.0.0-beta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from utils import * \n",
    "\n",
    "from models import LinearModel, LeNet, VGG16\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json') as raw_config:\n",
    "    config = json.load(raw_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data/train/0dc028fefe7c4461880a1d1920fec351.jpg', 4),\n",
       " ('data/train/d201e93220f74d5a89ab7d9dcd0d55a6.jpg', 2),\n",
       " ('data/train/b8063b8ca1ee467db5c379ee9e38c3a6.jpg', 1),\n",
       " ('data/train/7c2fe7165e754449acd10c74ab85af29.jpg', 1),\n",
       " ('data/train/2e38c3cff6d845a5b28b3b6c61acde51.jpg', 1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_source = build_source_from_metadata(pd.read_csv(config['model']['metadata_path']),\n",
    "                                        config['model']['data_path'], 'train')\n",
    "train_source[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img, label, model=None, size=(32, 32)):\n",
    "    img = tf.image.resize(img, size=size)\n",
    "    img = img / 255.0\n",
    "    return img, label\n",
    "\n",
    "dataset = make_dataset(train_source, preprocess_image, training=True, batch_size=3,\n",
    "                       num_epochs=1, num_parallel_calls=4)\n",
    "dataset = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=53, shape=(3,), dtype=int32, numpy=array([4, 2, 1], dtype=int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dataset)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow_batch_of_three(next(dataset), config['model']['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModel\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 15365     \n",
      "=================================================================\n",
      "Total params: 15,365\n",
      "Trainable params: 15,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "linear_model = LinearModel(config)\n",
    "print(linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0610 03:53:47.524817 140243699922752 training_utils.py:1436] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 0.5633 - accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3474 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2875 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3172 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3121 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2892 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2577 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2268 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2031 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1891 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1837 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1824 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1802 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1740 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1639 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1520 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1408 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1315 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1245 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "test = linear_model.train(overfit_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0610 03:54:29.713122 140243699922752 training_utils.py:1436] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "182/182 [==============================] - 2s 12ms/step - loss: 0.7139 - accuracy: 0.7366\n",
      "Epoch 2/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6960 - accuracy: 0.7431\n",
      "Epoch 3/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6926 - accuracy: 0.7452\n",
      "Epoch 4/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6893 - accuracy: 0.7472\n",
      "Epoch 5/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6862 - accuracy: 0.7486\n",
      "Epoch 6/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.6832 - accuracy: 0.7490\n",
      "Epoch 7/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.6802 - accuracy: 0.7514\n",
      "Epoch 8/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6774 - accuracy: 0.7517\n",
      "Epoch 9/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.6745 - accuracy: 0.7528\n",
      "Epoch 10/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.6718 - accuracy: 0.7538\n",
      "Epoch 11/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.6691 - accuracy: 0.7555\n",
      "Epoch 12/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6664 - accuracy: 0.7569\n",
      "Epoch 13/400\n",
      "182/182 [==============================] - 2s 11ms/step - loss: 0.6637 - accuracy: 0.7583\n",
      "Epoch 14/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6612 - accuracy: 0.7593\n",
      "Epoch 15/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.6586 - accuracy: 0.7603\n",
      "Epoch 16/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.6561 - accuracy: 0.7603\n",
      "Epoch 17/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6536 - accuracy: 0.7610\n",
      "Epoch 18/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6512 - accuracy: 0.7620\n",
      "Epoch 19/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6488 - accuracy: 0.7638\n",
      "Epoch 20/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6464 - accuracy: 0.7651\n",
      "Epoch 21/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6441 - accuracy: 0.7669\n",
      "Epoch 22/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6418 - accuracy: 0.7672\n",
      "Epoch 23/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6395 - accuracy: 0.7686\n",
      "Epoch 24/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6373 - accuracy: 0.7703\n",
      "Epoch 25/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6350 - accuracy: 0.7713\n",
      "Epoch 26/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6329 - accuracy: 0.7730\n",
      "Epoch 27/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6307 - accuracy: 0.7741\n",
      "Epoch 28/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6286 - accuracy: 0.7758\n",
      "Epoch 29/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6264 - accuracy: 0.7768\n",
      "Epoch 30/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6244 - accuracy: 0.7782\n",
      "Epoch 31/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6223 - accuracy: 0.7789\n",
      "Epoch 32/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.6203 - accuracy: 0.7792\n",
      "Epoch 33/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.6182 - accuracy: 0.7806\n",
      "Epoch 34/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6162 - accuracy: 0.7806\n",
      "Epoch 35/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6143 - accuracy: 0.7806\n",
      "Epoch 36/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6123 - accuracy: 0.7809\n",
      "Epoch 37/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6104 - accuracy: 0.7816\n",
      "Epoch 38/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6085 - accuracy: 0.7827\n",
      "Epoch 39/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.6066 - accuracy: 0.7844\n",
      "Epoch 40/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6047 - accuracy: 0.7858\n",
      "Epoch 41/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.6029 - accuracy: 0.7858\n",
      "Epoch 42/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.6010 - accuracy: 0.7865\n",
      "Epoch 43/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5992 - accuracy: 0.7868\n",
      "Epoch 44/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5974 - accuracy: 0.7871\n",
      "Epoch 45/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5956 - accuracy: 0.7882\n",
      "Epoch 46/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5939 - accuracy: 0.7889\n",
      "Epoch 47/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5921 - accuracy: 0.7895\n",
      "Epoch 48/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5904 - accuracy: 0.7906\n",
      "Epoch 49/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5887 - accuracy: 0.7920\n",
      "Epoch 50/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5870 - accuracy: 0.7923\n",
      "Epoch 51/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5853 - accuracy: 0.7933\n",
      "Epoch 52/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.5837 - accuracy: 0.7940\n",
      "Epoch 53/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.5820 - accuracy: 0.7947\n",
      "Epoch 54/400\n",
      "182/182 [==============================] - 2s 11ms/step - loss: 0.5804 - accuracy: 0.7950\n",
      "Epoch 55/400\n",
      "182/182 [==============================] - 2s 11ms/step - loss: 0.5788 - accuracy: 0.7950\n",
      "Epoch 56/400\n",
      "182/182 [==============================] - 2s 10ms/step - loss: 0.5772 - accuracy: 0.7964\n",
      "Epoch 57/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.5756 - accuracy: 0.7971\n",
      "Epoch 58/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5740 - accuracy: 0.7981\n",
      "Epoch 59/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5724 - accuracy: 0.7985\n",
      "Epoch 60/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.5709 - accuracy: 0.7988\n",
      "Epoch 61/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5693 - accuracy: 0.7988\n",
      "Epoch 62/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.5678 - accuracy: 0.7995\n",
      "Epoch 63/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.5663 - accuracy: 0.8002\n",
      "Epoch 64/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5648 - accuracy: 0.8009\n",
      "Epoch 65/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5633 - accuracy: 0.8016\n",
      "Epoch 66/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5618 - accuracy: 0.8016\n",
      "Epoch 67/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5604 - accuracy: 0.8016\n",
      "Epoch 68/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5589 - accuracy: 0.8026\n",
      "Epoch 69/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5575 - accuracy: 0.8033\n",
      "Epoch 70/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5560 - accuracy: 0.8033\n",
      "Epoch 71/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5546 - accuracy: 0.8043\n",
      "Epoch 72/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5532 - accuracy: 0.8050\n",
      "Epoch 73/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5518 - accuracy: 0.8054\n",
      "Epoch 74/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5504 - accuracy: 0.8061\n",
      "Epoch 75/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5491 - accuracy: 0.8074\n",
      "Epoch 76/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5477 - accuracy: 0.8074\n",
      "Epoch 77/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5463 - accuracy: 0.8085\n",
      "Epoch 78/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5450 - accuracy: 0.8091\n",
      "Epoch 79/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5437 - accuracy: 0.8091\n",
      "Epoch 80/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5423 - accuracy: 0.8091\n",
      "Epoch 81/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.5410 - accuracy: 0.8091\n",
      "Epoch 82/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5397 - accuracy: 0.8095\n",
      "Epoch 83/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5384 - accuracy: 0.8102\n",
      "Epoch 84/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5371 - accuracy: 0.8105\n",
      "Epoch 85/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5359 - accuracy: 0.8119\n",
      "Epoch 86/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5346 - accuracy: 0.8119\n",
      "Epoch 87/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5333 - accuracy: 0.8126\n",
      "Epoch 88/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5321 - accuracy: 0.8133\n",
      "Epoch 89/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5308 - accuracy: 0.8140\n",
      "Epoch 90/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5296 - accuracy: 0.8150\n",
      "Epoch 91/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5284 - accuracy: 0.8150\n",
      "Epoch 92/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5272 - accuracy: 0.8150\n",
      "Epoch 93/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5260 - accuracy: 0.8153\n",
      "Epoch 94/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5248 - accuracy: 0.8153\n",
      "Epoch 95/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5236 - accuracy: 0.8157\n",
      "Epoch 96/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5224 - accuracy: 0.8157\n",
      "Epoch 97/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5212 - accuracy: 0.8160\n",
      "Epoch 98/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5200 - accuracy: 0.8160\n",
      "Epoch 99/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5189 - accuracy: 0.8167\n",
      "Epoch 100/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5177 - accuracy: 0.8171\n",
      "Epoch 101/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5166 - accuracy: 0.8177\n",
      "Epoch 102/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5154 - accuracy: 0.8184\n",
      "Epoch 103/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5143 - accuracy: 0.8188\n",
      "Epoch 104/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5132 - accuracy: 0.8191\n",
      "Epoch 105/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5121 - accuracy: 0.8191\n",
      "Epoch 106/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5110 - accuracy: 0.8198\n",
      "Epoch 107/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5099 - accuracy: 0.8212\n",
      "Epoch 108/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5088 - accuracy: 0.8222\n",
      "Epoch 109/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.5077 - accuracy: 0.8232\n",
      "Epoch 110/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5066 - accuracy: 0.8243\n",
      "Epoch 111/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5055 - accuracy: 0.8246\n",
      "Epoch 112/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5045 - accuracy: 0.8253\n",
      "Epoch 113/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5034 - accuracy: 0.8257\n",
      "Epoch 114/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5023 - accuracy: 0.8263\n",
      "Epoch 115/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5013 - accuracy: 0.8267\n",
      "Epoch 116/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.5003 - accuracy: 0.8270\n",
      "Epoch 117/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4992 - accuracy: 0.8274\n",
      "Epoch 118/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4982 - accuracy: 0.8277\n",
      "Epoch 119/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4972 - accuracy: 0.8281\n",
      "Epoch 120/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4962 - accuracy: 0.8291\n",
      "Epoch 121/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4951 - accuracy: 0.8294\n",
      "Epoch 122/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4941 - accuracy: 0.8301\n",
      "Epoch 123/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4931 - accuracy: 0.8301\n",
      "Epoch 124/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4921 - accuracy: 0.8301\n",
      "Epoch 125/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4912 - accuracy: 0.8301\n",
      "Epoch 126/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4902 - accuracy: 0.8305\n",
      "Epoch 127/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4892 - accuracy: 0.8305\n",
      "Epoch 128/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4882 - accuracy: 0.8308\n",
      "Epoch 129/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4873 - accuracy: 0.8312\n",
      "Epoch 130/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4863 - accuracy: 0.8315\n",
      "Epoch 131/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4854 - accuracy: 0.8332\n",
      "Epoch 132/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4844 - accuracy: 0.8332\n",
      "Epoch 133/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4835 - accuracy: 0.8336\n",
      "Epoch 134/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4825 - accuracy: 0.8343\n",
      "Epoch 135/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4816 - accuracy: 0.8343\n",
      "Epoch 136/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4807 - accuracy: 0.8343\n",
      "Epoch 137/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4797 - accuracy: 0.8343\n",
      "Epoch 138/400\n",
      "182/182 [==============================] - 2s 10ms/step - loss: 0.4788 - accuracy: 0.8339\n",
      "Epoch 139/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4779 - accuracy: 0.8339\n",
      "Epoch 140/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4770 - accuracy: 0.8339\n",
      "Epoch 141/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4761 - accuracy: 0.8343\n",
      "Epoch 142/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4752 - accuracy: 0.8343\n",
      "Epoch 143/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4743 - accuracy: 0.8343\n",
      "Epoch 144/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4734 - accuracy: 0.8349\n",
      "Epoch 145/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4726 - accuracy: 0.8353\n",
      "Epoch 146/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4717 - accuracy: 0.8353\n",
      "Epoch 147/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.4708 - accuracy: 0.8356\n",
      "Epoch 148/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.4699 - accuracy: 0.8360\n",
      "Epoch 149/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4691 - accuracy: 0.8360\n",
      "Epoch 150/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4682 - accuracy: 0.8363\n",
      "Epoch 151/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4674 - accuracy: 0.8367\n",
      "Epoch 152/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4665 - accuracy: 0.8367\n",
      "Epoch 153/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4657 - accuracy: 0.8377\n",
      "Epoch 154/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4648 - accuracy: 0.8384\n",
      "Epoch 155/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.4640 - accuracy: 0.8391\n",
      "Epoch 156/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.4631 - accuracy: 0.8391\n",
      "Epoch 157/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4623 - accuracy: 0.8404\n",
      "Epoch 158/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4615 - accuracy: 0.8404\n",
      "Epoch 159/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4607 - accuracy: 0.8404\n",
      "Epoch 160/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4599 - accuracy: 0.8408\n",
      "Epoch 161/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4590 - accuracy: 0.8411\n",
      "Epoch 162/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4582 - accuracy: 0.8411\n",
      "Epoch 163/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4574 - accuracy: 0.8411\n",
      "Epoch 164/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4566 - accuracy: 0.8422\n",
      "Epoch 165/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4558 - accuracy: 0.8422\n",
      "Epoch 166/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4550 - accuracy: 0.8432\n",
      "Epoch 167/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4543 - accuracy: 0.8435\n",
      "Epoch 168/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4535 - accuracy: 0.8442\n",
      "Epoch 169/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4527 - accuracy: 0.8446\n",
      "Epoch 170/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4519 - accuracy: 0.8453\n",
      "Epoch 171/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4511 - accuracy: 0.8459\n",
      "Epoch 172/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4504 - accuracy: 0.8463\n",
      "Epoch 173/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4496 - accuracy: 0.8463\n",
      "Epoch 174/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4488 - accuracy: 0.8473\n",
      "Epoch 175/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4481 - accuracy: 0.8480\n",
      "Epoch 176/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4473 - accuracy: 0.8490\n",
      "Epoch 177/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4466 - accuracy: 0.8497\n",
      "Epoch 178/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4458 - accuracy: 0.8501\n",
      "Epoch 179/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4451 - accuracy: 0.8504\n",
      "Epoch 180/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4443 - accuracy: 0.8504\n",
      "Epoch 181/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4436 - accuracy: 0.8508\n",
      "Epoch 182/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4429 - accuracy: 0.8511\n",
      "Epoch 183/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4421 - accuracy: 0.8511\n",
      "Epoch 184/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4414 - accuracy: 0.8511\n",
      "Epoch 185/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4407 - accuracy: 0.8525\n",
      "Epoch 186/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4400 - accuracy: 0.8525\n",
      "Epoch 187/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4393 - accuracy: 0.8528\n",
      "Epoch 188/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4385 - accuracy: 0.8532\n",
      "Epoch 189/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4378 - accuracy: 0.8532\n",
      "Epoch 190/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4371 - accuracy: 0.8528\n",
      "Epoch 191/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4364 - accuracy: 0.8532\n",
      "Epoch 192/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4357 - accuracy: 0.8539\n",
      "Epoch 193/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4350 - accuracy: 0.8539\n",
      "Epoch 194/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4343 - accuracy: 0.8542\n",
      "Epoch 195/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4336 - accuracy: 0.8549\n",
      "Epoch 196/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4329 - accuracy: 0.8549\n",
      "Epoch 197/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4323 - accuracy: 0.8545\n",
      "Epoch 198/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4316 - accuracy: 0.8545\n",
      "Epoch 199/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4309 - accuracy: 0.8545\n",
      "Epoch 200/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4302 - accuracy: 0.8549\n",
      "Epoch 201/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4295 - accuracy: 0.8552\n",
      "Epoch 202/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4289 - accuracy: 0.8556\n",
      "Epoch 203/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4282 - accuracy: 0.8563\n",
      "Epoch 204/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.8573\n",
      "Epoch 205/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4269 - accuracy: 0.8573\n",
      "Epoch 206/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4262 - accuracy: 0.8576\n",
      "Epoch 207/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4255 - accuracy: 0.8583\n",
      "Epoch 208/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4249 - accuracy: 0.8583\n",
      "Epoch 209/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4242 - accuracy: 0.8587\n",
      "Epoch 210/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4236 - accuracy: 0.8590\n",
      "Epoch 211/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4229 - accuracy: 0.8597\n",
      "Epoch 212/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4223 - accuracy: 0.8604\n",
      "Epoch 213/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8607\n",
      "Epoch 214/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.8607\n",
      "Epoch 215/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4204 - accuracy: 0.8611\n",
      "Epoch 216/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4197 - accuracy: 0.8614\n",
      "Epoch 217/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4191 - accuracy: 0.8618\n",
      "Epoch 218/400\n",
      "182/182 [==============================] - 2s 10ms/step - loss: 0.4185 - accuracy: 0.8614\n",
      "Epoch 219/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4179 - accuracy: 0.8621\n",
      "Epoch 220/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4172 - accuracy: 0.8628\n",
      "Epoch 221/400\n",
      "182/182 [==============================] - 2s 11ms/step - loss: 0.4166 - accuracy: 0.8631\n",
      "Epoch 222/400\n",
      "182/182 [==============================] - 2s 11ms/step - loss: 0.4160 - accuracy: 0.8628\n",
      "Epoch 223/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4154 - accuracy: 0.8638\n",
      "Epoch 224/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4148 - accuracy: 0.8638\n",
      "Epoch 225/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4142 - accuracy: 0.8649\n",
      "Epoch 226/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4135 - accuracy: 0.8649\n",
      "Epoch 227/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4129 - accuracy: 0.8652\n",
      "Epoch 228/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4123 - accuracy: 0.8659\n",
      "Epoch 229/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4117 - accuracy: 0.8666\n",
      "Epoch 230/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.4111 - accuracy: 0.8666\n",
      "Epoch 231/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4105 - accuracy: 0.8669\n",
      "Epoch 232/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4099 - accuracy: 0.8669\n",
      "Epoch 233/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4094 - accuracy: 0.8673\n",
      "Epoch 234/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4088 - accuracy: 0.8669\n",
      "Epoch 235/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4082 - accuracy: 0.8676\n",
      "Epoch 236/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4076 - accuracy: 0.8676\n",
      "Epoch 237/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4070 - accuracy: 0.8676\n",
      "Epoch 238/400\n",
      "182/182 [==============================] - 2s 11ms/step - loss: 0.4064 - accuracy: 0.8676\n",
      "Epoch 239/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4058 - accuracy: 0.8676\n",
      "Epoch 240/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4053 - accuracy: 0.8683\n",
      "Epoch 241/400\n",
      "182/182 [==============================] - 2s 10ms/step - loss: 0.4047 - accuracy: 0.8686\n",
      "Epoch 242/400\n",
      "182/182 [==============================] - 2s 10ms/step - loss: 0.4041 - accuracy: 0.8686\n",
      "Epoch 243/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4036 - accuracy: 0.8693\n",
      "Epoch 244/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4030 - accuracy: 0.8693\n",
      "Epoch 245/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4024 - accuracy: 0.8700\n",
      "Epoch 246/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4019 - accuracy: 0.8700\n",
      "Epoch 247/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4013 - accuracy: 0.8700\n",
      "Epoch 248/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.4007 - accuracy: 0.8704\n",
      "Epoch 249/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.4002 - accuracy: 0.8707\n",
      "Epoch 250/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3996 - accuracy: 0.8710\n",
      "Epoch 251/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3991 - accuracy: 0.8710\n",
      "Epoch 252/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3985 - accuracy: 0.8714\n",
      "Epoch 253/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3980 - accuracy: 0.8717\n",
      "Epoch 254/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.3974 - accuracy: 0.8721\n",
      "Epoch 255/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3969 - accuracy: 0.8721\n",
      "Epoch 256/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3963 - accuracy: 0.8724\n",
      "Epoch 257/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3958 - accuracy: 0.8728\n",
      "Epoch 258/400\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.3953 - accuracy: 0.8731\n",
      "Epoch 259/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3947 - accuracy: 0.8731\n",
      "Epoch 260/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3942 - accuracy: 0.8735\n",
      "Epoch 261/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3936 - accuracy: 0.8738\n",
      "Epoch 262/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3931 - accuracy: 0.8738\n",
      "Epoch 263/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3926 - accuracy: 0.8738\n",
      "Epoch 264/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3921 - accuracy: 0.8745\n",
      "Epoch 265/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3915 - accuracy: 0.8745\n",
      "Epoch 266/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3910 - accuracy: 0.8748\n",
      "Epoch 267/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3905 - accuracy: 0.8755\n",
      "Epoch 268/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3900 - accuracy: 0.8755\n",
      "Epoch 269/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3894 - accuracy: 0.8755\n",
      "Epoch 270/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3889 - accuracy: 0.8762\n",
      "Epoch 271/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3884 - accuracy: 0.8762\n",
      "Epoch 272/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3879 - accuracy: 0.8762\n",
      "Epoch 273/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3874 - accuracy: 0.8762\n",
      "Epoch 274/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3869 - accuracy: 0.8762\n",
      "Epoch 275/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3864 - accuracy: 0.8762\n",
      "Epoch 276/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3859 - accuracy: 0.8769\n",
      "Epoch 277/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3854 - accuracy: 0.8769\n",
      "Epoch 278/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3849 - accuracy: 0.8769\n",
      "Epoch 279/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3844 - accuracy: 0.8772\n",
      "Epoch 280/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3839 - accuracy: 0.8772\n",
      "Epoch 281/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3834 - accuracy: 0.8776\n",
      "Epoch 282/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3829 - accuracy: 0.8776\n",
      "Epoch 283/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3824 - accuracy: 0.8779\n",
      "Epoch 284/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3819 - accuracy: 0.8779\n",
      "Epoch 285/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3814 - accuracy: 0.8779\n",
      "Epoch 286/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3809 - accuracy: 0.8779\n",
      "Epoch 287/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3804 - accuracy: 0.8779\n",
      "Epoch 288/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3799 - accuracy: 0.8779\n",
      "Epoch 289/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3794 - accuracy: 0.8786\n",
      "Epoch 290/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3790 - accuracy: 0.8796\n",
      "Epoch 291/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3785 - accuracy: 0.8800\n",
      "Epoch 292/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3780 - accuracy: 0.8800\n",
      "Epoch 293/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3775 - accuracy: 0.8800\n",
      "Epoch 294/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3770 - accuracy: 0.8800\n",
      "Epoch 295/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3766 - accuracy: 0.8807\n",
      "Epoch 296/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3761 - accuracy: 0.8810\n",
      "Epoch 297/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3756 - accuracy: 0.8814\n",
      "Epoch 298/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3752 - accuracy: 0.8814\n",
      "Epoch 299/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3747 - accuracy: 0.8820\n",
      "Epoch 300/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3742 - accuracy: 0.8824\n",
      "Epoch 301/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3738 - accuracy: 0.8824\n",
      "Epoch 302/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3733 - accuracy: 0.8824\n",
      "Epoch 303/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3728 - accuracy: 0.8838\n",
      "Epoch 304/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3724 - accuracy: 0.8841\n",
      "Epoch 305/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3719 - accuracy: 0.8841\n",
      "Epoch 306/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3715 - accuracy: 0.8841\n",
      "Epoch 307/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3710 - accuracy: 0.8841\n",
      "Epoch 308/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3705 - accuracy: 0.8851\n",
      "Epoch 309/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3701 - accuracy: 0.8855\n",
      "Epoch 310/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3696 - accuracy: 0.8858\n",
      "Epoch 311/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3692 - accuracy: 0.8858\n",
      "Epoch 312/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3687 - accuracy: 0.8862\n",
      "Epoch 313/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3683 - accuracy: 0.8862\n",
      "Epoch 314/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3678 - accuracy: 0.8862\n",
      "Epoch 315/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3674 - accuracy: 0.8862\n",
      "Epoch 316/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3670 - accuracy: 0.8862\n",
      "Epoch 317/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3665 - accuracy: 0.8872\n",
      "Epoch 318/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3661 - accuracy: 0.8876\n",
      "Epoch 319/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3656 - accuracy: 0.8872\n",
      "Epoch 320/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3652 - accuracy: 0.8879\n",
      "Epoch 321/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3648 - accuracy: 0.8879\n",
      "Epoch 322/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3643 - accuracy: 0.8886\n",
      "Epoch 323/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3639 - accuracy: 0.8889\n",
      "Epoch 324/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3635 - accuracy: 0.8893\n",
      "Epoch 325/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3630 - accuracy: 0.8900\n",
      "Epoch 326/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3626 - accuracy: 0.8900\n",
      "Epoch 327/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3622 - accuracy: 0.8896\n",
      "Epoch 328/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3617 - accuracy: 0.8900\n",
      "Epoch 329/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3613 - accuracy: 0.8903\n",
      "Epoch 330/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3609 - accuracy: 0.8903\n",
      "Epoch 331/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3605 - accuracy: 0.8906\n",
      "Epoch 332/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3600 - accuracy: 0.8906\n",
      "Epoch 333/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3596 - accuracy: 0.8910\n",
      "Epoch 334/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3592 - accuracy: 0.8910\n",
      "Epoch 335/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3588 - accuracy: 0.8910\n",
      "Epoch 336/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3584 - accuracy: 0.8910\n",
      "Epoch 337/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3579 - accuracy: 0.8913\n",
      "Epoch 338/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3575 - accuracy: 0.8920\n",
      "Epoch 339/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3571 - accuracy: 0.8924\n",
      "Epoch 340/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3567 - accuracy: 0.8934\n",
      "Epoch 341/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3563 - accuracy: 0.8937\n",
      "Epoch 342/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3559 - accuracy: 0.8937\n",
      "Epoch 343/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3555 - accuracy: 0.8941\n",
      "Epoch 344/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3551 - accuracy: 0.8941\n",
      "Epoch 345/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3547 - accuracy: 0.8941\n",
      "Epoch 346/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3543 - accuracy: 0.8944\n",
      "Epoch 347/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3539 - accuracy: 0.8944\n",
      "Epoch 348/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3535 - accuracy: 0.8944\n",
      "Epoch 349/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3531 - accuracy: 0.8944\n",
      "Epoch 350/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3527 - accuracy: 0.8944\n",
      "Epoch 351/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3523 - accuracy: 0.8948\n",
      "Epoch 352/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3519 - accuracy: 0.8955\n",
      "Epoch 353/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3515 - accuracy: 0.8958\n",
      "Epoch 354/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3511 - accuracy: 0.8961\n",
      "Epoch 355/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3507 - accuracy: 0.8965\n",
      "Epoch 356/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3503 - accuracy: 0.8965\n",
      "Epoch 357/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3499 - accuracy: 0.8968\n",
      "Epoch 358/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3495 - accuracy: 0.8968\n",
      "Epoch 359/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3491 - accuracy: 0.8975\n",
      "Epoch 360/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3487 - accuracy: 0.8975\n",
      "Epoch 361/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3483 - accuracy: 0.8975\n",
      "Epoch 362/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3479 - accuracy: 0.8982\n",
      "Epoch 363/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3476 - accuracy: 0.8986\n",
      "Epoch 364/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3472 - accuracy: 0.8986\n",
      "Epoch 365/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3468 - accuracy: 0.8986\n",
      "Epoch 366/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3464 - accuracy: 0.8986\n",
      "Epoch 367/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3460 - accuracy: 0.8986\n",
      "Epoch 368/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3457 - accuracy: 0.8986\n",
      "Epoch 369/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3453 - accuracy: 0.8986\n",
      "Epoch 370/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3449 - accuracy: 0.8986\n",
      "Epoch 371/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3445 - accuracy: 0.8989\n",
      "Epoch 372/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3441 - accuracy: 0.8989\n",
      "Epoch 373/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3438 - accuracy: 0.8992\n",
      "Epoch 374/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3434 - accuracy: 0.8996\n",
      "Epoch 375/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3430 - accuracy: 0.8999\n",
      "Epoch 376/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3426 - accuracy: 0.9006\n",
      "Epoch 377/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3423 - accuracy: 0.9006\n",
      "Epoch 378/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3419 - accuracy: 0.9006\n",
      "Epoch 379/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3415 - accuracy: 0.9006\n",
      "Epoch 380/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3412 - accuracy: 0.9013\n",
      "Epoch 381/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3408 - accuracy: 0.9020\n",
      "Epoch 382/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3404 - accuracy: 0.9023\n",
      "Epoch 383/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3401 - accuracy: 0.9023\n",
      "Epoch 384/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3397 - accuracy: 0.9023\n",
      "Epoch 385/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3394 - accuracy: 0.9023\n",
      "Epoch 386/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3390 - accuracy: 0.9023\n",
      "Epoch 387/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3386 - accuracy: 0.9027\n",
      "Epoch 388/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3383 - accuracy: 0.9027\n",
      "Epoch 389/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3379 - accuracy: 0.9030\n",
      "Epoch 390/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3376 - accuracy: 0.9027\n",
      "Epoch 391/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3372 - accuracy: 0.9030\n",
      "Epoch 392/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3368 - accuracy: 0.9030\n",
      "Epoch 393/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3365 - accuracy: 0.9030\n",
      "Epoch 394/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3361 - accuracy: 0.9030\n",
      "Epoch 395/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3358 - accuracy: 0.9030\n",
      "Epoch 396/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3354 - accuracy: 0.9034\n",
      "Epoch 397/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3351 - accuracy: 0.9034\n",
      "Epoch 398/400\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3347 - accuracy: 0.9034\n",
      "Epoch 399/400\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3344 - accuracy: 0.9037\n",
      "Epoch 400/400\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.3340 - accuracy: 0.9041\n"
     ]
    }
   ],
   "source": [
    "test = linear_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3316 - accuracy: 0.8876\n",
      "test\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 1.1909 - accuracy: 0.6405\n"
     ]
    }
   ],
   "source": [
    "linear_model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet\n",
      "\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "C1 (Conv2D)                  (None, 28, 28, 6)         456       \n",
      "_________________________________________________________________\n",
      "S2 (AveragePooling2D)        (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "C3 (Conv2D)                  (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "S4 (AveragePooling2D)        (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 1, 120)         48120     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "F6 (Dense)                   (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 5)                 425       \n",
      "=================================================================\n",
      "Total params: 61,581\n",
      "Trainable params: 61,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with open('config.json') as raw_config:\n",
    "    config = json.load(raw_config)\n",
    "\n",
    "lenet = LeNet(config)\n",
    "print(lenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0610 04:45:21.735181 140558240872256 training_utils.py:1436] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9058 - accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6187 - accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4273 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3019 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2184 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1627 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1250 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0980 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0777 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0620 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0500 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0410 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "lenet.train(overfit_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7064 - accuracy: 0.6000\n",
      "test\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1.6034 - accuracy: 0.5284\n"
     ]
    }
   ],
   "source": [
    "lenet.evaluate(overfit_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0610 04:45:41.921886 140558240872256 training_utils.py:1436] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "582/582 [==============================] - 8s 13ms/step - loss: 0.8887 - accuracy: 0.6668\n",
      "Epoch 2/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.7999 - accuracy: 0.6946\n",
      "Epoch 3/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.7358 - accuracy: 0.7184\n",
      "Epoch 4/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.6675 - accuracy: 0.7497\n",
      "Epoch 5/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.5913 - accuracy: 0.7854\n",
      "Epoch 6/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.5139 - accuracy: 0.8191\n",
      "Epoch 7/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.4369 - accuracy: 0.8477\n",
      "Epoch 8/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.3630 - accuracy: 0.8831\n",
      "Epoch 9/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.3007 - accuracy: 0.9075\n",
      "Epoch 10/400\n",
      "582/582 [==============================] - 7s 12ms/step - loss: 0.2339 - accuracy: 0.9302\n",
      "Epoch 11/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.1861 - accuracy: 0.9519\n",
      "Epoch 12/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.1529 - accuracy: 0.9587\n",
      "Epoch 13/400\n",
      "582/582 [==============================] - 7s 12ms/step - loss: 0.1153 - accuracy: 0.9708\n",
      "Epoch 14/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.0795 - accuracy: 0.9876\n",
      "Epoch 15/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.0713 - accuracy: 0.9856\n",
      "Epoch 16/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.0745 - accuracy: 0.9794\n",
      "Epoch 17/400\n",
      "582/582 [==============================] - 7s 12ms/step - loss: 0.0641 - accuracy: 0.9825\n",
      "Epoch 18/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.0513 - accuracy: 0.9869\n",
      "Epoch 19/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.0726 - accuracy: 0.9770\n",
      "Epoch 20/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.0302 - accuracy: 0.9935\n",
      "Epoch 21/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.0178 - accuracy: 0.9986\n",
      "Epoch 22/400\n",
      "582/582 [==============================] - 6s 10ms/step - loss: 0.0873 - accuracy: 0.9691\n",
      "Epoch 23/400\n",
      "582/582 [==============================] - 6s 11ms/step - loss: 0.0767 - accuracy: 0.9770\n",
      "Epoch 24/400\n",
      "197/582 [=========>....................] - ETA: 4s - loss: 0.0297 - accuracy: 0.9919"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-e0ca6a083b69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/image-classification/models.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, overfit_mode)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverfit_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverfit_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3508\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3510\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    571\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test = lenet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_17:0\", shape=(None, 244, 244, 3), dtype=float32)\n",
      "Tensor(\"max_pooling2d_7/Identity:0\", shape=(None, 120, 120, 64), dtype=float32)\n",
      "Tensor(\"max_pooling2d_8/Identity:0\", shape=(None, 58, 58, 128), dtype=float32)\n",
      "Tensor(\"max_pooling2d_9/Identity:0\", shape=(None, 27, 27, 256), dtype=float32)\n",
      "Tensor(\"max_pooling2d_10/Identity:0\", shape=(None, 10, 10, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with open('config.json') as raw_config:\n",
    "    config = json.load(raw_config)\n",
    "    \n",
    "net = VGG16(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
